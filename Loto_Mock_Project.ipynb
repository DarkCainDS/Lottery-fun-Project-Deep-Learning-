{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de prediccion linear"
      ],
      "metadata": {
        "id": "yGOPSXXntR2J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0qjd2eelM5O",
        "outputId": "ca3637e2-2530-4a03-a2c3-f2eabb7b121f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los próximos 7 números predichos son: [8, 9, 10, 11, 12, 13, 14]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Cargar el archivo CSV\n",
        "df = pd.read_csv('/content/Libro1.csv', delimiter=';')\n",
        "\n",
        "# Convertir la columna 'numeros' en una lista de listas\n",
        "numeros = df['Numero'].str.split('-').apply(lambda x: [int(i) for i in x])\n",
        "\n",
        "# Convertir en un único array 1D\n",
        "data = np.concatenate(numeros.values)\n",
        "def predict_next_seven_numbers(model, last_seven):\n",
        "    predictions = []\n",
        "\n",
        "    for _ in range(7):\n",
        "        X_next = np.array([[len(last_seven) + len(predictions)]])\n",
        "        next_pred = model.predict(X_next)[0]\n",
        "\n",
        "        # Redondear y convertir en entero\n",
        "        next_pred_rounded = int(round(next_pred))\n",
        "\n",
        "        predictions.append(next_pred_rounded)\n",
        "        last_seven = np.append(last_seven[1:], next_pred_rounded)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# Entrena el modelo con todos los datos\n",
        "X = np.arange(len(data)).reshape(-1, 1)\n",
        "model = LinearRegression().fit(X, data)\n",
        "\n",
        "# Asume que deseas predecir los próximos 7 números basándote en los últimos 7 números de tu dataset\n",
        "last_seven_numbers = data[-7:]\n",
        "predictions = predict_next_seven_numbers(model, last_seven_numbers)\n",
        "\n",
        "print(f\"Los próximos 7 números predichos son: {predictions}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Fecha'])\n",
        "print(df['Numero'])\n"
      ],
      "metadata": {
        "id": "ZXkqiwuCnHTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo usando tecna de LSMT para prediccion de datos\n"
      ],
      "metadata": {
        "id": "wcJ7c2kttYn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "\n",
        "# Cargar y preparar los datos\n",
        "df = pd.read_csv('/content/Libro2.csv', delimiter=';')\n",
        "numeros = df['Numero'].str.split('-').apply(lambda x: [int(i) for i in x])\n",
        "data = np.concatenate(numeros.values).reshape(-1, 1)\n",
        "\n",
        "# Reescalado de los datos\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_normalized = scaler.fit_transform(data)\n",
        "\n",
        "# Preparar los datos para LSTM\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset)-look_back):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 7\n",
        "X, y = create_dataset(data_normalized, look_back)\n",
        "X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Construir y entrenar modelo LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(1, look_back)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(X, y, epochs=100, batch_size=1)\n",
        "\n",
        "# ... (resto del código)\n",
        "\n",
        "# Predicciones\n",
        "predictions = []\n",
        "input_data = data_normalized[-look_back:].reshape(1, 1, look_back)\n",
        "\n",
        "for _ in range(7):\n",
        "    pred_normalized = model.predict(input_data)\n",
        "    pred_value = int(round(scaler.inverse_transform(pred_normalized).flatten()[0]))\n",
        "    predictions.append(pred_value)\n",
        "\n",
        "    # Desplaza la ventana de entrada\n",
        "    input_data = np.roll(input_data, -1)\n",
        "    input_data[0, 0, -1] = scaler.transform([[pred_value]])\n",
        "\n",
        "print(f\"Los próximos 7 números predichos son: {predictions}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PBK240-9o6Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo usando tecna de LSMT para prediccion de datos Usando dropout y early stop"
      ],
      "metadata": {
        "id": "JnVaxpxAtgLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Cargar y preparar los datos\n",
        "df = pd.read_csv('/content/Libro4.csv', delimiter=';')\n",
        "numeros = df['Numero'].str.split('-').apply(lambda x: [int(i) for i in x])\n",
        "data = np.concatenate(numeros.values).reshape(-1, 1)\n",
        "\n",
        "# Reescalado de los datos\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_normalized = scaler.fit_transform(data)\n",
        "\n",
        "# Preparar los datos para LSTM\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset)-look_back):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 7\n",
        "X, y = create_dataset(data_normalized, look_back)\n",
        "X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Construir y entrenar modelo LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(1, look_back)))\n",
        "model.add(Dropout(0.2))  # Capa Dropout después de la primera capa LSTM\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.2))  # Capa Dropout después de la segunda capa LSTM\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Aplicar EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "model.fit(X, y, epochs=50, batch_size=1, callbacks=[early_stopping])\n",
        "\n",
        "# Predicciones\n",
        "predictions = []\n",
        "input_data = data_normalized[-look_back:].reshape(1, 1, look_back)\n",
        "predicted_set = set()\n",
        "\n",
        "for _ in range(7):\n",
        "    pred_normalized = model.predict(input_data)\n",
        "    pred_value = int(round(scaler.inverse_transform(pred_normalized).flatten()[0]))\n",
        "\n",
        "    # Asegurar que no haya números repetidos\n",
        "    while pred_value in predicted_set:\n",
        "        pred_value += 1\n",
        "    predicted_set.add(pred_value)\n",
        "\n",
        "    predictions.append(pred_value)\n",
        "\n",
        "    # Desplaza la ventana de entrada\n",
        "    input_data = np.roll(input_data, -1)\n",
        "    input_data[0, 0, -1] = scaler.transform([[pred_value]])\n",
        "\n",
        "predictions = sorted(predictions)  # Ordenar las predicciones\n",
        "print(f\"Los próximos 7 números predichos son: {predictions}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKjJncFmtpT7",
        "outputId": "34890eba-2f59-46d6-e9ec-acff888ba18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "70/70 [==============================] - 9s 3ms/step - loss: 0.1487\n",
            "Epoch 2/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0730\n",
            "Epoch 3/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0685\n",
            "Epoch 4/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0643\n",
            "Epoch 5/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0546\n",
            "Epoch 6/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0494\n",
            "Epoch 7/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0533\n",
            "Epoch 8/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0498\n",
            "Epoch 9/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0460\n",
            "Epoch 10/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0505\n",
            "Epoch 11/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0501\n",
            "Epoch 12/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0509\n",
            "Epoch 13/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0463\n",
            "Epoch 14/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0437\n",
            "Epoch 15/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0444\n",
            "Epoch 16/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0487\n",
            "Epoch 17/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0417\n",
            "Epoch 18/50\n",
            "70/70 [==============================] - 0s 5ms/step - loss: 0.0459\n",
            "Epoch 19/50\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0453\n",
            "Epoch 20/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0429\n",
            "Epoch 21/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0440\n",
            "Epoch 22/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0493\n",
            "Epoch 23/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0426\n",
            "Epoch 24/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0406\n",
            "Epoch 25/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0451\n",
            "Epoch 26/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0452\n",
            "Epoch 27/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0400\n",
            "Epoch 28/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0418\n",
            "Epoch 29/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0393\n",
            "Epoch 30/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0463\n",
            "Epoch 31/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0458\n",
            "Epoch 32/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0436\n",
            "Epoch 33/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0406\n",
            "Epoch 34/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0400\n",
            "Epoch 35/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0400\n",
            "Epoch 36/50\n",
            "70/70 [==============================] - 0s 4ms/step - loss: 0.0432\n",
            "Epoch 37/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0431\n",
            "Epoch 38/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0430\n",
            "Epoch 39/50\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0420\n",
            "1/1 [==============================] - 1s 811ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Los próximos 7 números predichos son: [5, 8, 14, 15, 20, 30, 31]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardar el Modelo Existente\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QUhzV81CvWZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('mi_modelo_lstm.h5')\n"
      ],
      "metadata": {
        "id": "T_0Y5EIwvcUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar el Modelo Existente\n"
      ],
      "metadata": {
        "id": "f7IyBYC6vgbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('mi_modelo_lstm.h5')\n"
      ],
      "metadata": {
        "id": "u6DAUdMkvkHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenar con Nuevos Datos\n"
      ],
      "metadata": {
        "id": "RaWXY2W1vmc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suponiendo que 'nuevos_datos.csv' es tu archivo con nuevos datos\n",
        "df_nuevo = pd.read_csv('/content/Libro1.csv', delimiter=';')\n",
        "numeros_nuevo = df_nuevo['Numero'].str.split('-').apply(lambda x: [int(i) for i in x])\n",
        "data_nuevo = np.concatenate(numeros_nuevo.values).reshape(-1, 1)\n",
        "data_normalized_nuevo = scaler.transform(data_nuevo)  # Usa el mismo scaler\n",
        "X_nuevo, y_nuevo = create_dataset(data_normalized_nuevo, look_back)\n",
        "X_nuevo = np.reshape(X_nuevo, (X_nuevo.shape[0], 1, X_nuevo.shape[1]))\n",
        "\n",
        "# Entrenamiento con los nuevos datos\n",
        "model.fit(X_nuevo, y_nuevo, epochs=100, batch_size=1, callbacks=[early_stopping])\n",
        "\n",
        "# ... (Luego de entrenar con los nuevos datos)\n",
        "\n",
        "# Predicciones\n",
        "predictions = []\n",
        "input_data = data_normalized_nuevo[-look_back:].reshape(1, 1, look_back)\n",
        "\n",
        "for _ in range(7):\n",
        "    pred_normalized = model.predict(input_data)\n",
        "    pred_value = int(round(scaler.inverse_transform(pred_normalized).flatten()[0]))\n",
        "    predictions.append(pred_value)\n",
        "\n",
        "    # Desplaza la ventana de entrada\n",
        "    input_data = np.roll(input_data, -1)\n",
        "    input_data[0, 0, -1] = scaler.transform([[pred_value]])\n",
        "\n",
        "print(f\"Los próximos 7 números predichos son: {predictions}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Ye3WGxLbvqYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo usando tecna de LSMT para prediccion de datos Usando dropout y early stop con 6 numeros"
      ],
      "metadata": {
        "id": "Mw7x3Ie41zyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Cargar y preparar los datos\n",
        "df = pd.read_csv('/content/resultadosV2.csv', delimiter=';')\n",
        "numeros = df['Numero'].str.split('-').apply(lambda x: [int(i) for i in x])\n",
        "data = np.concatenate(numeros.values).reshape(-1, 1)\n",
        "\n",
        "# Reescalado de los datos\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_normalized = scaler.fit_transform(data)\n",
        "\n",
        "# Preparar los datos para LSTM\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset)-look_back):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 7\n",
        "X, y = create_dataset(data_normalized, look_back)\n",
        "X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Construir y entrenar modelo LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(1, look_back)))\n",
        "model.add(Dropout(0.2))  # Capa Dropout después de la primera capa LSTM\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.2))  # Capa Dropout después de la segunda capa LSTM\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Aplicar EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "model.fit(X, y, epochs=10, batch_size=1, callbacks=[early_stopping])\n",
        "\n",
        "# Predicciones\n",
        "predictions = []\n",
        "input_data = data_normalized[-look_back:].reshape(1, 1, look_back)\n",
        "predicted_set = set()\n",
        "\n",
        "for _ in range(6):\n",
        "    pred_normalized = model.predict(input_data)\n",
        "    pred_value = int(round(scaler.inverse_transform(pred_normalized).flatten()[0]))\n",
        "\n",
        "    # Asegurar que no haya números repetidos\n",
        "    while pred_value in predicted_set:\n",
        "        pred_value += 1\n",
        "    predicted_set.add(pred_value)\n",
        "\n",
        "    predictions.append(pred_value)\n",
        "\n",
        "    # Desplaza la ventana de entrada\n",
        "    input_data = np.roll(input_data, -1)\n",
        "    input_data[0, 0, -1] = scaler.transform([[pred_value]])\n",
        "\n",
        "predictions = sorted(predictions)  # Ordenar las predicciones\n",
        "print(f\"Los próximos 6 números predichos son: {predictions}\")\n"
      ],
      "metadata": {
        "id": "DXfS2Rhy1xFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf62b300-f97f-4928-d7e4-f9ec6283fc7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "19751/19751 [==============================] - 60s 3ms/step - loss: 0.0239\n",
            "Epoch 2/10\n",
            "19751/19751 [==============================] - 56s 3ms/step - loss: 0.0156\n",
            "Epoch 3/10\n",
            "19751/19751 [==============================] - 56s 3ms/step - loss: 0.0142\n",
            "Epoch 4/10\n",
            "19751/19751 [==============================] - 56s 3ms/step - loss: 0.0139\n",
            "Epoch 5/10\n",
            "19751/19751 [==============================] - 58s 3ms/step - loss: 0.0136\n",
            "Epoch 6/10\n",
            "19751/19751 [==============================] - 56s 3ms/step - loss: 0.0136\n",
            "Epoch 7/10\n",
            "19751/19751 [==============================] - 57s 3ms/step - loss: 0.0135\n",
            "Epoch 8/10\n",
            "19751/19751 [==============================] - 56s 3ms/step - loss: 0.0135\n",
            "Epoch 9/10\n",
            "19751/19751 [==============================] - 56s 3ms/step - loss: 0.0134\n",
            "Epoch 10/10\n",
            "19751/19751 [==============================] - 58s 3ms/step - loss: 0.0134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo usando tecna de LSMT para prediccion de datos Usando dropout y early stop con 1 numero"
      ],
      "metadata": {
        "id": "aVVFG8MH2Px6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Cargar y preparar los datos\n",
        "df = pd.read_csv('/content/resultados_1number.csv', delimiter=';')\n",
        "data = df['Numero'].values.reshape(-1, 1)  # directly reshape the data\n",
        "\n",
        "\n",
        "# Reescalado de los datos\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_normalized = scaler.fit_transform(data)\n",
        "\n",
        "# Preparar los datos para LSTM\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset)-look_back):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 7\n",
        "X, y = create_dataset(data_normalized, look_back)\n",
        "X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Construir y entrenar modelo LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(1, look_back)))\n",
        "model.add(Dropout(0.2))  # Capa Dropout después de la primera capa LSTM\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.2))  # Capa Dropout después de la segunda capa LSTM\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Aplicar EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "model.fit(X, y, epochs=200, batch_size=1, callbacks=[early_stopping])\n",
        "\n",
        "# Predicciones\n",
        "predictions = []\n",
        "input_data = data_normalized[-look_back:].reshape(1, 1, look_back)\n",
        "predicted_set = set()\n",
        "\n",
        "for _ in range(1):\n",
        "    pred_normalized = model.predict(input_data)\n",
        "    pred_value = int(round(scaler.inverse_transform(pred_normalized).flatten()[0]))\n",
        "\n",
        "    # Asegurar que no haya números repetidos\n",
        "    while pred_value in predicted_set:\n",
        "        pred_value += 1\n",
        "    predicted_set.add(pred_value)\n",
        "\n",
        "    predictions.append(pred_value)\n",
        "\n",
        "    # Desplaza la ventana de entrada\n",
        "    input_data = np.roll(input_data, -1)\n",
        "    input_data[0, 0, -1] = scaler.transform([[pred_value]])\n",
        "\n",
        "predictions = sorted(predictions)  # Ordenar las predicciones\n",
        "print(f\"El próximo número predicho es: {predictions[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0pgpIrf2SP4",
        "outputId": "38c9d758-6dc6-478e-dcf4-df81479224cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "329/329 [==============================] - 4s 3ms/step - loss: 0.1159\n",
            "Epoch 2/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.1010\n",
            "Epoch 3/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0993\n",
            "Epoch 4/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0972\n",
            "Epoch 5/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.1024\n",
            "Epoch 6/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0982\n",
            "Epoch 7/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0971\n",
            "Epoch 8/200\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0985\n",
            "Epoch 9/200\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.1003\n",
            "Epoch 10/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0968\n",
            "Epoch 11/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0973\n",
            "Epoch 12/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0972\n",
            "Epoch 13/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0980\n",
            "Epoch 14/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0943\n",
            "Epoch 15/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0964\n",
            "Epoch 16/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0941\n",
            "Epoch 17/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0966\n",
            "Epoch 18/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0971\n",
            "Epoch 19/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0973\n",
            "Epoch 20/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0962\n",
            "Epoch 21/200\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0949\n",
            "Epoch 22/200\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0957\n",
            "Epoch 23/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0971\n",
            "Epoch 24/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0962\n",
            "Epoch 25/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0948\n",
            "Epoch 26/200\n",
            "329/329 [==============================] - 1s 3ms/step - loss: 0.0953\n",
            "1/1 [==============================] - 1s 733ms/step\n",
            "El próximo número predicho es: 20\n"
          ]
        }
      ]
    }
  ]
}